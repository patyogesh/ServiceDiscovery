[2016-04-27 20:23:33,171] TRACE Controller 1 epoch 72 started leader election for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:23:33,174] ERROR Controller 1 epoch 72 initiated state change for partition [pipeline,1] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [pipeline,1] is alive. Live brokers are: [Set()], Assigned replicas are: [List(1, 2)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:75)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:205)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:120)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:117)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:117)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:70)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:332)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:163)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:84)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply$mcZ$sp(KafkaController.scala:1172)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$SessionExpirationListener.handleNewSession(KafkaController.scala:1170)
	at org.I0Itec.zkclient.ZkClient$6.run(ZkClient.java:734)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
[2016-04-27 20:23:33,174] TRACE Controller 1 epoch 72 started leader election for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:23:33,178] ERROR Controller 1 epoch 72 initiated state change for partition [pipeline,2] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [pipeline,2] is alive. Live brokers are: [Set()], Assigned replicas are: [List(2, 1)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:75)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:205)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:120)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:117)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:117)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:70)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:332)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:163)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:84)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply$mcZ$sp(KafkaController.scala:1172)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$SessionExpirationListener.handleNewSession(KafkaController.scala:1170)
	at org.I0Itec.zkclient.ZkClient$6.run(ZkClient.java:734)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
[2016-04-27 20:23:33,178] TRACE Controller 1 epoch 72 started leader election for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:23:33,181] ERROR Controller 1 epoch 72 initiated state change for partition [pipeline,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [pipeline,0] is alive. Live brokers are: [Set()], Assigned replicas are: [List(2, 1)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:75)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:205)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:120)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:117)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:117)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:70)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:332)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:163)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:84)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply$mcZ$sp(KafkaController.scala:1172)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$SessionExpirationListener.handleNewSession(KafkaController.scala:1170)
	at org.I0Itec.zkclient.ZkClient$6.run(ZkClient.java:734)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
[2016-04-27 20:23:33,526] TRACE Controller 1 epoch 72 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:54,ControllerEpoch:71) to broker 2 for partition pipeline-1 (state.change.logger)
[2016-04-27 20:23:33,526] TRACE Controller 1 epoch 72 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:71) to broker 2 for partition pipeline-0 (state.change.logger)
[2016-04-27 20:23:33,526] TRACE Controller 1 epoch 72 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:71) to broker 2 for partition pipeline-2 (state.change.logger)
[2016-04-27 20:23:33,527] TRACE Controller 1 epoch 72 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:54,ControllerEpoch:71) to broker 1 for partition pipeline-1 (state.change.logger)
[2016-04-27 20:23:33,527] TRACE Controller 1 epoch 72 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:71) to broker 1 for partition pipeline-0 (state.change.logger)
[2016-04-27 20:23:33,527] TRACE Controller 1 epoch 72 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:71) to broker 1 for partition pipeline-2 (state.change.logger)
[2016-04-27 20:23:33,527] TRACE Controller 1 epoch 72 changed state of replica 2 for partition [pipeline,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-04-27 20:23:33,527] TRACE Controller 1 epoch 72 changed state of replica 2 for partition [pipeline,1] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-04-27 20:23:33,527] TRACE Controller 1 epoch 72 changed state of replica 1 for partition [pipeline,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-04-27 20:23:33,527] TRACE Controller 1 epoch 72 changed state of replica 1 for partition [pipeline,1] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-04-27 20:23:33,527] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:54,ControllerEpoch:71),ReplicationFactor:2),AllReplicas:1,2) for partition [pipeline,1] in response to UpdateMetadata request sent by controller 1 epoch 72 with correlation id 0 (state.change.logger)
[2016-04-27 20:23:33,527] TRACE Controller 1 epoch 72 changed state of replica 1 for partition [pipeline,2] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-04-27 20:23:33,527] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:71),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,2] in response to UpdateMetadata request sent by controller 1 epoch 72 with correlation id 0 (state.change.logger)
[2016-04-27 20:23:33,528] TRACE Controller 1 epoch 72 changed state of replica 2 for partition [pipeline,2] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-04-27 20:23:33,528] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:71),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,0] in response to UpdateMetadata request sent by controller 1 epoch 72 with correlation id 0 (state.change.logger)
[2016-04-27 20:23:33,528] TRACE Controller 1 epoch 72 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,LeaderEpoch:54,ControllerEpoch:71) to broker 2 for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:23:33,528] TRACE Controller 1 epoch 72 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:71) to broker 2 for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:23:33,528] TRACE Controller 1 epoch 72 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:71) to broker 2 for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:23:33,528] TRACE Controller 1 epoch 72 received response {error_code=0} for a request sent to broker Node(1, 10.0.0.9, 9092) (state.change.logger)
[2016-04-27 20:23:33,528] TRACE Controller 1 epoch 72 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,2,LeaderEpoch:54,ControllerEpoch:71) to broker 1 for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:23:33,528] TRACE Controller 1 epoch 72 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:71) to broker 1 for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:23:33,528] TRACE Controller 1 epoch 72 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:71) to broker 1 for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:23:33,528] TRACE Controller 1 epoch 72 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:54,ControllerEpoch:71) to broker 2 for partition pipeline-1 (state.change.logger)
[2016-04-27 20:23:33,528] TRACE Controller 1 epoch 72 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:71) to broker 2 for partition pipeline-0 (state.change.logger)
[2016-04-27 20:23:33,528] TRACE Controller 1 epoch 72 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:71) to broker 2 for partition pipeline-2 (state.change.logger)
[2016-04-27 20:23:33,528] TRACE Controller 1 epoch 72 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:54,ControllerEpoch:71) to broker 1 for partition pipeline-1 (state.change.logger)
[2016-04-27 20:23:33,528] TRACE Controller 1 epoch 72 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:71) to broker 1 for partition pipeline-0 (state.change.logger)
[2016-04-27 20:23:33,528] TRACE Controller 1 epoch 72 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:71) to broker 1 for partition pipeline-2 (state.change.logger)
[2016-04-27 20:23:33,528] TRACE Controller 1 epoch 72 started leader election for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:23:33,528] TRACE Broker 1 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:54,ControllerEpoch:71),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 1 epoch 72 for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:23:33,528] TRACE Broker 1 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:71),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 1 epoch 72 for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:23:33,528] TRACE Broker 1 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:71),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 1 epoch 72 for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:23:33,528] WARN Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 72 for partition [pipeline,1] since its associated leader epoch 54 is old. Current leader epoch is 54 (state.change.logger)
[2016-04-27 20:23:33,528] WARN Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 72 for partition [pipeline,2] since its associated leader epoch 57 is old. Current leader epoch is 57 (state.change.logger)
[2016-04-27 20:23:33,528] WARN Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 72 for partition [pipeline,0] since its associated leader epoch 57 is old. Current leader epoch is 57 (state.change.logger)
[2016-04-27 20:23:33,528] TRACE Controller 1 epoch 72 received response {error_code=0} for a request sent to broker Node(2, 10.0.0.9, 9093) (state.change.logger)
[2016-04-27 20:23:33,529] TRACE Controller 1 epoch 72 received response {error_code=0,partitions=[{topic=pipeline,partition=1,error_code=13},{topic=pipeline,partition=2,error_code=13},{topic=pipeline,partition=0,error_code=13}]} for a request sent to broker Node(1, 10.0.0.9, 9092) (state.change.logger)
[2016-04-27 20:23:33,529] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:54,ControllerEpoch:71),ReplicationFactor:2),AllReplicas:1,2) for partition [pipeline,1] in response to UpdateMetadata request sent by controller 1 epoch 72 with correlation id 2 (state.change.logger)
[2016-04-27 20:23:33,529] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:71),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,2] in response to UpdateMetadata request sent by controller 1 epoch 72 with correlation id 2 (state.change.logger)
[2016-04-27 20:23:33,529] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:71),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,0] in response to UpdateMetadata request sent by controller 1 epoch 72 with correlation id 2 (state.change.logger)
[2016-04-27 20:23:33,529] TRACE Controller 1 epoch 72 received response {error_code=0,partitions=[{topic=pipeline,partition=1,error_code=13},{topic=pipeline,partition=2,error_code=13},{topic=pipeline,partition=0,error_code=13}]} for a request sent to broker Node(2, 10.0.0.9, 9093) (state.change.logger)
[2016-04-27 20:23:33,529] TRACE Controller 1 epoch 72 received response {error_code=0} for a request sent to broker Node(1, 10.0.0.9, 9092) (state.change.logger)
[2016-04-27 20:23:33,529] TRACE Controller 1 epoch 72 received response {error_code=0} for a request sent to broker Node(2, 10.0.0.9, 9093) (state.change.logger)
[2016-04-27 20:23:33,531] TRACE Controller 1 epoch 72 elected leader 1 for Offline partition [pipeline,1] (state.change.logger)
[2016-04-27 20:23:33,531] TRACE Controller 1 epoch 72 changed partition [pipeline,1] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-04-27 20:23:33,531] TRACE Controller 1 epoch 72 started leader election for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:23:33,533] TRACE Controller 1 epoch 72 elected leader 1 for Offline partition [pipeline,2] (state.change.logger)
[2016-04-27 20:23:33,533] TRACE Controller 1 epoch 72 changed partition [pipeline,2] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-04-27 20:23:33,533] TRACE Controller 1 epoch 72 started leader election for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:23:33,535] TRACE Controller 1 epoch 72 elected leader 1 for Offline partition [pipeline,0] (state.change.logger)
[2016-04-27 20:23:33,535] TRACE Controller 1 epoch 72 changed partition [pipeline,0] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-04-27 20:23:33,535] TRACE Controller 1 epoch 72 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,LeaderEpoch:55,ControllerEpoch:72) to broker 2 for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:23:33,535] TRACE Controller 1 epoch 72 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72) to broker 2 for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:23:33,536] TRACE Controller 1 epoch 72 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72) to broker 2 for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:23:33,536] TRACE Controller 1 epoch 72 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,2,LeaderEpoch:55,ControllerEpoch:72) to broker 1 for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:23:33,536] TRACE Controller 1 epoch 72 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72) to broker 1 for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:23:33,536] TRACE Controller 1 epoch 72 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72) to broker 1 for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:23:33,536] TRACE Controller 1 epoch 72 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:55,ControllerEpoch:72) to broker 2 for partition pipeline-1 (state.change.logger)
[2016-04-27 20:23:33,536] TRACE Controller 1 epoch 72 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72) to broker 2 for partition pipeline-0 (state.change.logger)
[2016-04-27 20:23:33,536] TRACE Controller 1 epoch 72 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72) to broker 2 for partition pipeline-2 (state.change.logger)
[2016-04-27 20:23:33,536] TRACE Controller 1 epoch 72 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:55,ControllerEpoch:72) to broker 1 for partition pipeline-1 (state.change.logger)
[2016-04-27 20:23:33,536] TRACE Controller 1 epoch 72 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72) to broker 1 for partition pipeline-0 (state.change.logger)
[2016-04-27 20:23:33,536] TRACE Controller 1 epoch 72 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72) to broker 1 for partition pipeline-2 (state.change.logger)
[2016-04-27 20:23:33,536] TRACE Broker 1 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:55,ControllerEpoch:72),ReplicationFactor:2),AllReplicas:1,2) correlation id 3 from controller 1 epoch 72 for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:23:33,536] TRACE Broker 1 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72),ReplicationFactor:2),AllReplicas:2,1) correlation id 3 from controller 1 epoch 72 for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:23:33,536] TRACE Broker 1 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72),ReplicationFactor:2),AllReplicas:2,1) correlation id 3 from controller 1 epoch 72 for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:23:33,536] TRACE Broker 1 handling LeaderAndIsr request correlationId 3 from controller 1 epoch 72 starting the become-leader transition for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:23:33,536] TRACE Broker 1 handling LeaderAndIsr request correlationId 3 from controller 1 epoch 72 starting the become-leader transition for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:23:33,536] TRACE Broker 1 handling LeaderAndIsr request correlationId 3 from controller 1 epoch 72 starting the become-leader transition for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:23:33,536] INFO Broker 1 skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 72 for partition [pipeline,2] since it is already the leader for the partition. (state.change.logger)
[2016-04-27 20:23:33,536] INFO Broker 1 skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 72 for partition [pipeline,0] since it is already the leader for the partition. (state.change.logger)
[2016-04-27 20:23:33,536] INFO Broker 1 skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 72 for partition [pipeline,1] since it is already the leader for the partition. (state.change.logger)
[2016-04-27 20:23:33,536] TRACE Broker 1 completed LeaderAndIsr request correlationId 3 from controller 1 epoch 72 for the become-leader transition for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:23:33,536] TRACE Broker 1 completed LeaderAndIsr request correlationId 3 from controller 1 epoch 72 for the become-leader transition for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:23:33,537] TRACE Broker 1 completed LeaderAndIsr request correlationId 3 from controller 1 epoch 72 for the become-leader transition for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:23:33,537] TRACE Controller 1 epoch 72 received response {error_code=0,partitions=[{topic=pipeline,partition=1,error_code=0},{topic=pipeline,partition=2,error_code=0},{topic=pipeline,partition=0,error_code=0}]} for a request sent to broker Node(1, 10.0.0.9, 9092) (state.change.logger)
[2016-04-27 20:23:33,537] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:55,ControllerEpoch:72),ReplicationFactor:2),AllReplicas:1,2) for partition [pipeline,1] in response to UpdateMetadata request sent by controller 1 epoch 72 with correlation id 4 (state.change.logger)
[2016-04-27 20:23:33,537] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,2] in response to UpdateMetadata request sent by controller 1 epoch 72 with correlation id 4 (state.change.logger)
[2016-04-27 20:23:33,537] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,0] in response to UpdateMetadata request sent by controller 1 epoch 72 with correlation id 4 (state.change.logger)
[2016-04-27 20:23:33,537] TRACE Controller 1 epoch 72 received response {error_code=0,partitions=[{topic=pipeline,partition=1,error_code=0},{topic=pipeline,partition=2,error_code=0},{topic=pipeline,partition=0,error_code=0}]} for a request sent to broker Node(2, 10.0.0.9, 9093) (state.change.logger)
[2016-04-27 20:23:33,537] TRACE Controller 1 epoch 72 received response {error_code=0} for a request sent to broker Node(1, 10.0.0.9, 9092) (state.change.logger)
[2016-04-27 20:23:33,537] TRACE Controller 1 epoch 72 received response {error_code=0} for a request sent to broker Node(2, 10.0.0.9, 9093) (state.change.logger)
[2016-04-27 20:23:39,027] TRACE Controller 1 epoch 72 started leader election for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:23:39,030] ERROR Controller 1 epoch 72 encountered error while electing leader for partition [pipeline,2] due to: Preferred replica 2 for partition [pipeline,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":58,"isr":[1]}]. (state.change.logger)
[2016-04-27 20:23:39,030] ERROR Controller 1 epoch 72 initiated state change for partition [pipeline,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [pipeline,2] due to: Preferred replica 2 for partition [pipeline,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":58,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map2.foreach(Map.scala:137)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [pipeline,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":58,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-04-27 20:23:39,031] TRACE Controller 1 epoch 72 started leader election for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:23:39,033] ERROR Controller 1 epoch 72 encountered error while electing leader for partition [pipeline,0] due to: Preferred replica 2 for partition [pipeline,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":58,"isr":[1]}]. (state.change.logger)
[2016-04-27 20:23:39,033] ERROR Controller 1 epoch 72 initiated state change for partition [pipeline,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [pipeline,0] due to: Preferred replica 2 for partition [pipeline,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":58,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map2.foreach(Map.scala:137)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [pipeline,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":58,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-04-27 20:25:23,165] TRACE Controller 1 epoch 73 started leader election for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:25:23,169] ERROR Controller 1 epoch 73 initiated state change for partition [pipeline,1] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [pipeline,1] is alive. Live brokers are: [Set()], Assigned replicas are: [List(1, 2)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:75)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:205)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:120)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:117)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:117)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:70)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:332)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:163)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:84)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply$mcZ$sp(KafkaController.scala:1172)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$SessionExpirationListener.handleNewSession(KafkaController.scala:1170)
	at org.I0Itec.zkclient.ZkClient$6.run(ZkClient.java:734)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
[2016-04-27 20:25:23,169] TRACE Controller 1 epoch 73 started leader election for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:25:23,173] ERROR Controller 1 epoch 73 initiated state change for partition [pipeline,2] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [pipeline,2] is alive. Live brokers are: [Set()], Assigned replicas are: [List(2, 1)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:75)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:205)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:120)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:117)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:117)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:70)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:332)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:163)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:84)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply$mcZ$sp(KafkaController.scala:1172)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$SessionExpirationListener.handleNewSession(KafkaController.scala:1170)
	at org.I0Itec.zkclient.ZkClient$6.run(ZkClient.java:734)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
[2016-04-27 20:25:23,174] TRACE Controller 1 epoch 73 started leader election for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:25:23,176] ERROR Controller 1 epoch 73 initiated state change for partition [pipeline,0] from OfflinePartition to OnlinePartition failed (state.change.logger)
kafka.common.NoReplicaOnlineException: No replica for partition [pipeline,0] is alive. Live brokers are: [Set()], Assigned replicas are: [List(2, 1)]
	at kafka.controller.OfflinePartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:75)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:205)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:120)
	at kafka.controller.PartitionStateMachine$$anonfun$triggerOnlinePartitionStateChange$3.apply(PartitionStateMachine.scala:117)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777)
	at kafka.controller.PartitionStateMachine.triggerOnlinePartitionStateChange(PartitionStateMachine.scala:117)
	at kafka.controller.PartitionStateMachine.startup(PartitionStateMachine.scala:70)
	at kafka.controller.KafkaController.onControllerFailover(KafkaController.scala:332)
	at kafka.controller.KafkaController$$anonfun$1.apply$mcV$sp(KafkaController.scala:163)
	at kafka.server.ZookeeperLeaderElector.elect(ZookeeperLeaderElector.scala:84)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply$mcZ$sp(KafkaController.scala:1172)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.controller.KafkaController$SessionExpirationListener$$anonfun$handleNewSession$1.apply(KafkaController.scala:1170)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$SessionExpirationListener.handleNewSession(KafkaController.scala:1170)
	at org.I0Itec.zkclient.ZkClient$6.run(ZkClient.java:734)
	at org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:71)
[2016-04-27 20:25:23,877] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:55,ControllerEpoch:72) to broker 2 for partition pipeline-1 (state.change.logger)
[2016-04-27 20:25:23,877] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72) to broker 2 for partition pipeline-0 (state.change.logger)
[2016-04-27 20:25:23,877] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72) to broker 2 for partition pipeline-2 (state.change.logger)
[2016-04-27 20:25:23,878] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:55,ControllerEpoch:72) to broker 1 for partition pipeline-1 (state.change.logger)
[2016-04-27 20:25:23,878] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72) to broker 1 for partition pipeline-0 (state.change.logger)
[2016-04-27 20:25:23,878] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72) to broker 1 for partition pipeline-2 (state.change.logger)
[2016-04-27 20:25:23,878] TRACE Controller 1 epoch 73 changed state of replica 2 for partition [pipeline,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-04-27 20:25:23,878] TRACE Controller 1 epoch 73 changed state of replica 2 for partition [pipeline,1] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-04-27 20:25:23,878] TRACE Controller 1 epoch 73 changed state of replica 1 for partition [pipeline,0] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-04-27 20:25:23,878] TRACE Controller 1 epoch 73 changed state of replica 1 for partition [pipeline,1] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-04-27 20:25:23,878] TRACE Controller 1 epoch 73 changed state of replica 1 for partition [pipeline,2] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-04-27 20:25:23,878] TRACE Controller 1 epoch 73 changed state of replica 2 for partition [pipeline,2] from ReplicaDeletionIneligible to OnlineReplica (state.change.logger)
[2016-04-27 20:25:23,878] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:55,ControllerEpoch:72),ReplicationFactor:2),AllReplicas:1,2) for partition [pipeline,1] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 0 (state.change.logger)
[2016-04-27 20:25:23,878] TRACE Controller 1 epoch 73 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,LeaderEpoch:55,ControllerEpoch:72) to broker 2 for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:25:23,878] TRACE Controller 1 epoch 73 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72) to broker 2 for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:25:23,878] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,2] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 0 (state.change.logger)
[2016-04-27 20:25:23,878] TRACE Controller 1 epoch 73 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72) to broker 2 for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:25:23,878] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,0] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 0 (state.change.logger)
[2016-04-27 20:25:23,878] TRACE Controller 1 epoch 73 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,2,LeaderEpoch:55,ControllerEpoch:72) to broker 1 for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:25:23,878] TRACE Controller 1 epoch 73 received response {error_code=0} for a request sent to broker Node(1, 10.0.0.9, 9092) (state.change.logger)
[2016-04-27 20:25:23,878] TRACE Controller 1 epoch 73 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72) to broker 1 for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:25:23,878] TRACE Controller 1 epoch 73 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72) to broker 1 for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:25:23,879] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:55,ControllerEpoch:72) to broker 2 for partition pipeline-1 (state.change.logger)
[2016-04-27 20:25:23,879] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72) to broker 2 for partition pipeline-0 (state.change.logger)
[2016-04-27 20:25:23,879] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72) to broker 2 for partition pipeline-2 (state.change.logger)
[2016-04-27 20:25:23,879] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:55,ControllerEpoch:72) to broker 1 for partition pipeline-1 (state.change.logger)
[2016-04-27 20:25:23,879] TRACE Broker 1 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:55,ControllerEpoch:72),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 1 epoch 73 for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:25:23,879] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72) to broker 1 for partition pipeline-0 (state.change.logger)
[2016-04-27 20:25:23,879] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72) to broker 1 for partition pipeline-2 (state.change.logger)
[2016-04-27 20:25:23,879] TRACE Broker 1 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 1 epoch 73 for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:25:23,879] TRACE Broker 1 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 1 epoch 73 for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:25:23,879] WARN Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 73 for partition [pipeline,1] since its associated leader epoch 55 is old. Current leader epoch is 55 (state.change.logger)
[2016-04-27 20:25:23,879] TRACE Controller 1 epoch 73 started leader election for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:25:23,879] WARN Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 73 for partition [pipeline,2] since its associated leader epoch 58 is old. Current leader epoch is 58 (state.change.logger)
[2016-04-27 20:25:23,879] WARN Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 73 for partition [pipeline,0] since its associated leader epoch 58 is old. Current leader epoch is 58 (state.change.logger)
[2016-04-27 20:25:23,879] TRACE Controller 1 epoch 73 received response {error_code=0,partitions=[{topic=pipeline,partition=1,error_code=13},{topic=pipeline,partition=2,error_code=13},{topic=pipeline,partition=0,error_code=13}]} for a request sent to broker Node(1, 10.0.0.9, 9092) (state.change.logger)
[2016-04-27 20:25:23,879] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:55,ControllerEpoch:72),ReplicationFactor:2),AllReplicas:1,2) for partition [pipeline,1] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 2 (state.change.logger)
[2016-04-27 20:25:23,879] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,2] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 2 (state.change.logger)
[2016-04-27 20:25:23,879] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:58,ControllerEpoch:72),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,0] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 2 (state.change.logger)
[2016-04-27 20:25:23,880] TRACE Controller 1 epoch 73 received response {error_code=0} for a request sent to broker Node(1, 10.0.0.9, 9092) (state.change.logger)
[2016-04-27 20:25:23,880] TRACE Controller 1 epoch 73 received response {error_code=0} for a request sent to broker Node(2, 10.0.0.9, 9093) (state.change.logger)
[2016-04-27 20:25:23,880] TRACE Controller 1 epoch 73 received response {error_code=0,partitions=[{topic=pipeline,partition=1,error_code=13},{topic=pipeline,partition=2,error_code=13},{topic=pipeline,partition=0,error_code=13}]} for a request sent to broker Node(2, 10.0.0.9, 9093) (state.change.logger)
[2016-04-27 20:25:23,881] TRACE Controller 1 epoch 73 received response {error_code=0} for a request sent to broker Node(2, 10.0.0.9, 9093) (state.change.logger)
[2016-04-27 20:25:23,882] TRACE Controller 1 epoch 73 elected leader 1 for Offline partition [pipeline,1] (state.change.logger)
[2016-04-27 20:25:23,882] TRACE Controller 1 epoch 73 changed partition [pipeline,1] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-04-27 20:25:23,882] TRACE Controller 1 epoch 73 started leader election for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:25:23,884] TRACE Controller 1 epoch 73 elected leader 1 for Offline partition [pipeline,2] (state.change.logger)
[2016-04-27 20:25:23,884] TRACE Controller 1 epoch 73 changed partition [pipeline,2] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-04-27 20:25:23,884] TRACE Controller 1 epoch 73 started leader election for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:25:23,885] TRACE Controller 1 epoch 73 elected leader 1 for Offline partition [pipeline,0] (state.change.logger)
[2016-04-27 20:25:23,886] TRACE Controller 1 epoch 73 changed partition [pipeline,0] from OfflinePartition to OnlinePartition with leader 1 (state.change.logger)
[2016-04-27 20:25:23,886] TRACE Controller 1 epoch 73 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,LeaderEpoch:56,ControllerEpoch:73) to broker 2 for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:25:23,886] TRACE Controller 1 epoch 73 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 2 for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:25:23,886] TRACE Controller 1 epoch 73 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 2 for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:25:23,886] TRACE Controller 1 epoch 73 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,2,LeaderEpoch:56,ControllerEpoch:73) to broker 1 for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:25:23,886] TRACE Controller 1 epoch 73 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 1 for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:25:23,886] TRACE Controller 1 epoch 73 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 1 for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:25:23,886] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:56,ControllerEpoch:73) to broker 2 for partition pipeline-1 (state.change.logger)
[2016-04-27 20:25:23,886] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 2 for partition pipeline-0 (state.change.logger)
[2016-04-27 20:25:23,886] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 2 for partition pipeline-2 (state.change.logger)
[2016-04-27 20:25:23,886] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:56,ControllerEpoch:73) to broker 1 for partition pipeline-1 (state.change.logger)
[2016-04-27 20:25:23,886] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 1 for partition pipeline-0 (state.change.logger)
[2016-04-27 20:25:23,886] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 1 for partition pipeline-2 (state.change.logger)
[2016-04-27 20:25:23,886] TRACE Broker 1 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:56,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:1,2) correlation id 3 from controller 1 epoch 73 for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:25:23,886] TRACE Broker 1 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:2,1) correlation id 3 from controller 1 epoch 73 for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:25:23,886] TRACE Broker 1 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:2,1) correlation id 3 from controller 1 epoch 73 for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:25:23,886] TRACE Broker 1 handling LeaderAndIsr request correlationId 3 from controller 1 epoch 73 starting the become-leader transition for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:25:23,886] TRACE Broker 1 handling LeaderAndIsr request correlationId 3 from controller 1 epoch 73 starting the become-leader transition for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:25:23,886] TRACE Broker 1 handling LeaderAndIsr request correlationId 3 from controller 1 epoch 73 starting the become-leader transition for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:25:23,886] INFO Broker 1 skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 73 for partition [pipeline,2] since it is already the leader for the partition. (state.change.logger)
[2016-04-27 20:25:23,886] INFO Broker 1 skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 73 for partition [pipeline,0] since it is already the leader for the partition. (state.change.logger)
[2016-04-27 20:25:23,886] INFO Broker 1 skipped the become-leader state change after marking its partition as leader with correlation id 3 from controller 1 epoch 73 for partition [pipeline,1] since it is already the leader for the partition. (state.change.logger)
[2016-04-27 20:25:23,886] TRACE Broker 1 completed LeaderAndIsr request correlationId 3 from controller 1 epoch 73 for the become-leader transition for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:25:23,886] TRACE Broker 1 completed LeaderAndIsr request correlationId 3 from controller 1 epoch 73 for the become-leader transition for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:25:23,887] TRACE Broker 1 completed LeaderAndIsr request correlationId 3 from controller 1 epoch 73 for the become-leader transition for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:25:23,887] TRACE Controller 1 epoch 73 received response {error_code=0,partitions=[{topic=pipeline,partition=1,error_code=0},{topic=pipeline,partition=2,error_code=0},{topic=pipeline,partition=0,error_code=0}]} for a request sent to broker Node(1, 10.0.0.9, 9092) (state.change.logger)
[2016-04-27 20:25:23,887] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:56,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:1,2) for partition [pipeline,1] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 4 (state.change.logger)
[2016-04-27 20:25:23,887] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,2] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 4 (state.change.logger)
[2016-04-27 20:25:23,887] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,0] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 4 (state.change.logger)
[2016-04-27 20:25:23,887] TRACE Controller 1 epoch 73 received response {error_code=0,partitions=[{topic=pipeline,partition=1,error_code=0},{topic=pipeline,partition=2,error_code=0},{topic=pipeline,partition=0,error_code=0}]} for a request sent to broker Node(2, 10.0.0.9, 9093) (state.change.logger)
[2016-04-27 20:25:23,887] TRACE Controller 1 epoch 73 received response {error_code=0} for a request sent to broker Node(1, 10.0.0.9, 9092) (state.change.logger)
[2016-04-27 20:25:23,888] TRACE Controller 1 epoch 73 received response {error_code=0} for a request sent to broker Node(2, 10.0.0.9, 9093) (state.change.logger)
[2016-04-27 20:25:28,184] TRACE Controller 1 epoch 73 started leader election for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:25:28,187] ERROR Controller 1 epoch 73 encountered error while electing leader for partition [pipeline,2] due to: Preferred replica 2 for partition [pipeline,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":59,"isr":[1]}]. (state.change.logger)
[2016-04-27 20:25:28,187] ERROR Controller 1 epoch 73 initiated state change for partition [pipeline,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [pipeline,2] due to: Preferred replica 2 for partition [pipeline,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":59,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map2.foreach(Map.scala:137)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [pipeline,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":59,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-04-27 20:25:28,188] TRACE Controller 1 epoch 73 started leader election for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:25:28,191] ERROR Controller 1 epoch 73 encountered error while electing leader for partition [pipeline,0] due to: Preferred replica 2 for partition [pipeline,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":59,"isr":[1]}]. (state.change.logger)
[2016-04-27 20:25:28,191] ERROR Controller 1 epoch 73 initiated state change for partition [pipeline,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [pipeline,0] due to: Preferred replica 2 for partition [pipeline,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":59,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map2.foreach(Map.scala:137)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [pipeline,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":59,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-04-27 20:49:19,187] TRACE Controller 1 epoch 73 changed state of replica 2 for partition [pipeline,1] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-04-27 20:49:19,189] TRACE Controller 1 epoch 73 changed state of replica 2 for partition [pipeline,2] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-04-27 20:49:19,190] TRACE Controller 1 epoch 73 changed state of replica 2 for partition [pipeline,0] from OnlineReplica to OfflineReplica (state.change.logger)
[2016-04-27 20:49:19,190] TRACE Controller 1 epoch 73 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:73) to broker 1 for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:49:19,191] TRACE Controller 1 epoch 73 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 1 for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:49:19,191] TRACE Controller 1 epoch 73 sending become-leader LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 1 for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:49:19,191] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:73) to broker 1 for partition pipeline-1 (state.change.logger)
[2016-04-27 20:49:19,191] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 1 for partition pipeline-0 (state.change.logger)
[2016-04-27 20:49:19,191] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 1 for partition pipeline-2 (state.change.logger)
[2016-04-27 20:49:19,197] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:73) to broker 1 for partition pipeline-1 (state.change.logger)
[2016-04-27 20:49:19,197] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 1 for partition pipeline-0 (state.change.logger)
[2016-04-27 20:49:19,197] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 1 for partition pipeline-2 (state.change.logger)
[2016-04-27 20:49:19,495] TRACE Broker 1 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:1,2) correlation id 5 from controller 1 epoch 73 for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:49:19,495] TRACE Broker 1 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:2,1) correlation id 5 from controller 1 epoch 73 for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:49:19,495] TRACE Broker 1 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:2,1) correlation id 5 from controller 1 epoch 73 for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:49:19,495] WARN Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 5 epoch 73 for partition [pipeline,2] since its associated leader epoch 59 is old. Current leader epoch is 59 (state.change.logger)
[2016-04-27 20:49:19,495] WARN Broker 1 ignoring LeaderAndIsr request from controller 1 with correlation id 5 epoch 73 for partition [pipeline,0] since its associated leader epoch 59 is old. Current leader epoch is 59 (state.change.logger)
[2016-04-27 20:49:19,495] TRACE Broker 1 handling LeaderAndIsr request correlationId 5 from controller 1 epoch 73 starting the become-leader transition for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:49:19,495] INFO Broker 1 skipped the become-leader state change after marking its partition as leader with correlation id 5 from controller 1 epoch 73 for partition [pipeline,1] since it is already the leader for the partition. (state.change.logger)
[2016-04-27 20:49:19,495] TRACE Broker 1 completed LeaderAndIsr request correlationId 5 from controller 1 epoch 73 for the become-leader transition for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:49:19,495] TRACE Controller 1 epoch 73 received response {error_code=0,partitions=[{topic=pipeline,partition=1,error_code=0},{topic=pipeline,partition=2,error_code=13},{topic=pipeline,partition=0,error_code=13}]} for a request sent to broker Node(1, 10.0.0.9, 9092) (state.change.logger)
[2016-04-27 20:49:19,496] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:1,2) for partition [pipeline,1] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 6 (state.change.logger)
[2016-04-27 20:49:19,496] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,2] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 6 (state.change.logger)
[2016-04-27 20:49:19,496] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,0] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 6 (state.change.logger)
[2016-04-27 20:49:19,496] TRACE Controller 1 epoch 73 received response {error_code=0} for a request sent to broker Node(1, 10.0.0.9, 9092) (state.change.logger)
[2016-04-27 20:49:19,496] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:57,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:1,2) for partition [pipeline,1] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 7 (state.change.logger)
[2016-04-27 20:49:19,496] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,2] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 7 (state.change.logger)
[2016-04-27 20:49:19,496] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,0] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 7 (state.change.logger)
[2016-04-27 20:49:19,496] TRACE Controller 1 epoch 73 received response {error_code=0} for a request sent to broker Node(1, 10.0.0.9, 9092) (state.change.logger)
[2016-04-27 20:49:20,712] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:57,ControllerEpoch:73) to broker 1 for partition pipeline-1 (state.change.logger)
[2016-04-27 20:49:20,713] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:57,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:1,2) for partition [pipeline,1] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 8 (state.change.logger)
[2016-04-27 20:49:20,713] TRACE Controller 1 epoch 73 received response {error_code=0} for a request sent to broker Node(1, 10.0.0.9, 9092) (state.change.logger)
[2016-04-27 20:49:25,375] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:57,ControllerEpoch:73) to broker 2 for partition pipeline-1 (state.change.logger)
[2016-04-27 20:49:25,375] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 2 for partition pipeline-0 (state.change.logger)
[2016-04-27 20:49:25,375] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 2 for partition pipeline-2 (state.change.logger)
[2016-04-27 20:49:25,375] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:57,ControllerEpoch:73) to broker 1 for partition pipeline-1 (state.change.logger)
[2016-04-27 20:49:25,375] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 1 for partition pipeline-0 (state.change.logger)
[2016-04-27 20:49:25,375] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 1 for partition pipeline-2 (state.change.logger)
[2016-04-27 20:49:25,376] TRACE Controller 1 epoch 73 changed state of replica 2 for partition [pipeline,1] from OfflineReplica to OnlineReplica (state.change.logger)
[2016-04-27 20:49:25,376] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:57,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:1,2) for partition [pipeline,1] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 9 (state.change.logger)
[2016-04-27 20:49:25,376] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,2] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 9 (state.change.logger)
[2016-04-27 20:49:25,376] TRACE Controller 1 epoch 73 changed state of replica 2 for partition [pipeline,2] from OfflineReplica to OnlineReplica (state.change.logger)
[2016-04-27 20:49:25,376] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,0] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 9 (state.change.logger)
[2016-04-27 20:49:25,376] TRACE Controller 1 epoch 73 changed state of replica 2 for partition [pipeline,0] from OfflineReplica to OnlineReplica (state.change.logger)
[2016-04-27 20:49:25,376] TRACE Controller 1 epoch 73 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,2,LeaderEpoch:57,ControllerEpoch:73) to broker 2 for partition [pipeline,1] (state.change.logger)
[2016-04-27 20:49:25,376] TRACE Controller 1 epoch 73 received response {error_code=0} for a request sent to broker Node(1, 10.0.0.9, 9092) (state.change.logger)
[2016-04-27 20:49:25,376] TRACE Controller 1 epoch 73 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 2 for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:49:25,376] TRACE Controller 1 epoch 73 sending become-follower LeaderAndIsr request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 2 for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:49:25,376] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:57,ControllerEpoch:73) to broker 2 for partition pipeline-1 (state.change.logger)
[2016-04-27 20:49:25,376] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 2 for partition pipeline-0 (state.change.logger)
[2016-04-27 20:49:25,376] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 2 for partition pipeline-2 (state.change.logger)
[2016-04-27 20:49:25,376] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:57,ControllerEpoch:73) to broker 1 for partition pipeline-1 (state.change.logger)
[2016-04-27 20:49:25,376] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 1 for partition pipeline-0 (state.change.logger)
[2016-04-27 20:49:25,376] TRACE Controller 1 epoch 73 sending UpdateMetadata request (Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73) to broker 1 for partition pipeline-2 (state.change.logger)
[2016-04-27 20:49:25,376] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:57,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:1,2) for partition [pipeline,1] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 10 (state.change.logger)
[2016-04-27 20:49:25,376] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,2] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 10 (state.change.logger)
[2016-04-27 20:49:25,376] TRACE Broker 1 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:59,ControllerEpoch:73),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,0] in response to UpdateMetadata request sent by controller 1 epoch 73 with correlation id 10 (state.change.logger)
[2016-04-27 20:49:25,377] TRACE Controller 1 epoch 73 received response {error_code=0} for a request sent to broker Node(2, 10.0.0.9, 9093) (state.change.logger)
[2016-04-27 20:49:25,377] TRACE Controller 1 epoch 73 received response {error_code=0} for a request sent to broker Node(1, 10.0.0.9, 9092) (state.change.logger)
[2016-04-27 20:49:25,378] TRACE Controller 1 epoch 73 received response {error_code=0,partitions=[{topic=pipeline,partition=1,error_code=0},{topic=pipeline,partition=2,error_code=13},{topic=pipeline,partition=0,error_code=13}]} for a request sent to broker Node(2, 10.0.0.9, 9093) (state.change.logger)
[2016-04-27 20:49:25,379] TRACE Controller 1 epoch 73 received response {error_code=0} for a request sent to broker Node(2, 10.0.0.9, 9093) (state.change.logger)
[2016-04-27 20:50:34,434] TRACE Controller 1 epoch 73 started leader election for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:50:34,435] ERROR Controller 1 epoch 73 encountered error while electing leader for partition [pipeline,2] due to: Preferred replica 2 for partition [pipeline,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":59,"isr":[1]}]. (state.change.logger)
[2016-04-27 20:50:34,435] ERROR Controller 1 epoch 73 initiated state change for partition [pipeline,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [pipeline,2] due to: Preferred replica 2 for partition [pipeline,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":59,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map2.foreach(Map.scala:137)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [pipeline,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":59,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-04-27 20:50:34,436] TRACE Controller 1 epoch 73 started leader election for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:50:34,437] ERROR Controller 1 epoch 73 encountered error while electing leader for partition [pipeline,0] due to: Preferred replica 2 for partition [pipeline,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":59,"isr":[1]}]. (state.change.logger)
[2016-04-27 20:50:34,437] ERROR Controller 1 epoch 73 initiated state change for partition [pipeline,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [pipeline,0] due to: Preferred replica 2 for partition [pipeline,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":59,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map2.foreach(Map.scala:137)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [pipeline,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":59,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-04-27 20:55:34,856] TRACE Controller 1 epoch 73 started leader election for partition [pipeline,2] (state.change.logger)
[2016-04-27 20:55:34,858] ERROR Controller 1 epoch 73 encountered error while electing leader for partition [pipeline,2] due to: Preferred replica 2 for partition [pipeline,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":59,"isr":[1]}]. (state.change.logger)
[2016-04-27 20:55:34,858] ERROR Controller 1 epoch 73 initiated state change for partition [pipeline,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [pipeline,2] due to: Preferred replica 2 for partition [pipeline,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":59,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map2.foreach(Map.scala:137)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [pipeline,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":59,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-04-27 20:55:34,859] TRACE Controller 1 epoch 73 started leader election for partition [pipeline,0] (state.change.logger)
[2016-04-27 20:55:34,859] ERROR Controller 1 epoch 73 encountered error while electing leader for partition [pipeline,0] due to: Preferred replica 2 for partition [pipeline,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":59,"isr":[1]}]. (state.change.logger)
[2016-04-27 20:55:34,859] ERROR Controller 1 epoch 73 initiated state change for partition [pipeline,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [pipeline,0] due to: Preferred replica 2 for partition [pipeline,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":59,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map2.foreach(Map.scala:137)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [pipeline,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":59,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
