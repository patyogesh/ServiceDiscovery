[2016-04-26 12:18:59,410] TRACE Controller 2 epoch 35 started leader election for partition [pipeline,2] (state.change.logger)
[2016-04-26 12:19:00,054] ERROR Controller 2 epoch 35 encountered error while electing leader for partition [pipeline,2] due to: Preferred replica 2 for partition [pipeline,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":29,"isr":[1]}]. (state.change.logger)
[2016-04-26 12:19:00,054] ERROR Controller 2 epoch 35 initiated state change for partition [pipeline,2] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [pipeline,2] due to: Preferred replica 2 for partition [pipeline,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":29,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map2.foreach(Map.scala:137)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [pipeline,2] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":29,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-04-26 12:19:00,067] TRACE Controller 2 epoch 35 started leader election for partition [pipeline,0] (state.change.logger)
[2016-04-26 12:19:00,068] ERROR Controller 2 epoch 35 encountered error while electing leader for partition [pipeline,0] due to: Preferred replica 2 for partition [pipeline,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":29,"isr":[1]}]. (state.change.logger)
[2016-04-26 12:19:00,068] ERROR Controller 2 epoch 35 initiated state change for partition [pipeline,0] from OnlinePartition to OnlinePartition failed (state.change.logger)
kafka.common.StateChangeFailedException: encountered error while electing leader for partition [pipeline,0] due to: Preferred replica 2 for partition [pipeline,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":29,"isr":[1]}].
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:368)
	at kafka.controller.PartitionStateMachine.kafka$controller$PartitionStateMachine$$handleStateChange(PartitionStateMachine.scala:207)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:146)
	at kafka.controller.PartitionStateMachine$$anonfun$handleStateChanges$2.apply(PartitionStateMachine.scala:145)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:79)
	at kafka.controller.PartitionStateMachine.handleStateChanges(PartitionStateMachine.scala:145)
	at kafka.controller.KafkaController.onPreferredReplicaElection(KafkaController.scala:662)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply$mcV$sp(KafkaController.scala:1225)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18$$anonfun$apply$5.apply(KafkaController.scala:1220)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:262)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1217)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4$$anonfun$apply$18.apply(KafkaController.scala:1215)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:99)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1215)
	at kafka.controller.KafkaController$$anonfun$kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance$4.apply(KafkaController.scala:1194)
	at scala.collection.immutable.Map$Map2.foreach(Map.scala:137)
	at kafka.controller.KafkaController.kafka$controller$KafkaController$$checkAndTriggerPartitionRebalance(KafkaController.scala:1194)
	at kafka.controller.KafkaController$$anonfun$onControllerFailover$1.apply$mcV$sp(KafkaController.scala:344)
	at kafka.utils.KafkaScheduler$$anonfun$1.apply$mcV$sp(KafkaScheduler.scala:110)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:60)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: kafka.common.StateChangeFailedException: Preferred replica 2 for partition [pipeline,0] is either not alive or not in the isr. Current leader and ISR: [{"leader":1,"leader_epoch":29,"isr":[1]}]
	at kafka.controller.PreferredReplicaPartitionLeaderSelector.selectLeader(PartitionLeaderSelector.scala:159)
	at kafka.controller.PartitionStateMachine.electLeaderForPartition(PartitionStateMachine.scala:345)
	... 31 more
[2016-04-26 12:19:01,281] TRACE Controller 2 epoch 0 sending UpdateMetadata request (Leader:1,ISR:1,2,LeaderEpoch:26,ControllerEpoch:35) to broker 2 for partition pipeline-1 (state.change.logger)
[2016-04-26 12:19:01,305] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:26,ControllerEpoch:35),ReplicationFactor:2),AllReplicas:1,2) for partition [pipeline,1] in response to UpdateMetadata request sent by controller 1 epoch 36 with correlation id 0 (state.change.logger)
[2016-04-26 12:19:01,306] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:29,ControllerEpoch:35),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,2] in response to UpdateMetadata request sent by controller 1 epoch 36 with correlation id 0 (state.change.logger)
[2016-04-26 12:19:01,306] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:29,ControllerEpoch:35),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,0] in response to UpdateMetadata request sent by controller 1 epoch 36 with correlation id 0 (state.change.logger)
[2016-04-26 12:19:01,307] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:26,ControllerEpoch:35),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 1 epoch 36 for partition [pipeline,1] (state.change.logger)
[2016-04-26 12:19:01,307] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:29,ControllerEpoch:35),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 1 epoch 36 for partition [pipeline,2] (state.change.logger)
[2016-04-26 12:19:01,307] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:29,ControllerEpoch:35),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 1 epoch 36 for partition [pipeline,0] (state.change.logger)
[2016-04-26 12:19:01,307] WARN Broker 2 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 36 for partition [pipeline,1] since its associated leader epoch 26 is old. Current leader epoch is 26 (state.change.logger)
[2016-04-26 12:19:01,307] WARN Broker 2 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 36 for partition [pipeline,2] since its associated leader epoch 29 is old. Current leader epoch is 29 (state.change.logger)
[2016-04-26 12:19:01,307] WARN Broker 2 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 36 for partition [pipeline,0] since its associated leader epoch 29 is old. Current leader epoch is 29 (state.change.logger)
[2016-04-26 12:19:01,308] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:26,ControllerEpoch:35),ReplicationFactor:2),AllReplicas:1,2) for partition [pipeline,1] in response to UpdateMetadata request sent by controller 1 epoch 36 with correlation id 2 (state.change.logger)
[2016-04-26 12:19:01,308] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:29,ControllerEpoch:35),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,2] in response to UpdateMetadata request sent by controller 1 epoch 36 with correlation id 2 (state.change.logger)
[2016-04-26 12:19:01,308] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:29,ControllerEpoch:35),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,0] in response to UpdateMetadata request sent by controller 1 epoch 36 with correlation id 2 (state.change.logger)
[2016-04-26 12:19:01,314] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:27,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:1,2) correlation id 3 from controller 1 epoch 36 for partition [pipeline,1] (state.change.logger)
[2016-04-26 12:19:01,314] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:30,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:2,1) correlation id 3 from controller 1 epoch 36 for partition [pipeline,2] (state.change.logger)
[2016-04-26 12:19:01,314] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:30,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:2,1) correlation id 3 from controller 1 epoch 36 for partition [pipeline,0] (state.change.logger)
[2016-04-26 12:19:01,314] TRACE Broker 2 handling LeaderAndIsr request correlationId 3 from controller 1 epoch 36 starting the become-follower transition for partition [pipeline,2] (state.change.logger)
[2016-04-26 12:19:01,314] TRACE Broker 2 handling LeaderAndIsr request correlationId 3 from controller 1 epoch 36 starting the become-follower transition for partition [pipeline,0] (state.change.logger)
[2016-04-26 12:19:01,314] TRACE Broker 2 handling LeaderAndIsr request correlationId 3 from controller 1 epoch 36 starting the become-follower transition for partition [pipeline,1] (state.change.logger)
[2016-04-26 12:19:01,314] INFO Broker 2 skipped the become-follower state change after marking its partition as follower with correlation id 3 from controller 1 epoch 36 for partition [pipeline,2] since the new leader 1 is the same as the old leader (state.change.logger)
[2016-04-26 12:19:01,314] INFO Broker 2 skipped the become-follower state change after marking its partition as follower with correlation id 3 from controller 1 epoch 36 for partition [pipeline,0] since the new leader 1 is the same as the old leader (state.change.logger)
[2016-04-26 12:19:01,314] INFO Broker 2 skipped the become-follower state change after marking its partition as follower with correlation id 3 from controller 1 epoch 36 for partition [pipeline,1] since the new leader 1 is the same as the old leader (state.change.logger)
[2016-04-26 12:19:01,321] TRACE Broker 2 completed LeaderAndIsr request correlationId 3 from controller 1 epoch 36 for the become-follower transition for partition [pipeline,2] (state.change.logger)
[2016-04-26 12:19:01,321] TRACE Broker 2 completed LeaderAndIsr request correlationId 3 from controller 1 epoch 36 for the become-follower transition for partition [pipeline,0] (state.change.logger)
[2016-04-26 12:19:01,321] TRACE Broker 2 completed LeaderAndIsr request correlationId 3 from controller 1 epoch 36 for the become-follower transition for partition [pipeline,1] (state.change.logger)
[2016-04-26 12:19:01,343] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:27,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:1,2) correlation id 0 from controller 1 epoch 37 for partition [pipeline,1] (state.change.logger)
[2016-04-26 12:19:01,343] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:30,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:2,1) correlation id 0 from controller 1 epoch 37 for partition [pipeline,2] (state.change.logger)
[2016-04-26 12:19:01,343] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:30,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:2,1) correlation id 0 from controller 1 epoch 37 for partition [pipeline,0] (state.change.logger)
[2016-04-26 12:19:01,343] WARN Broker 2 ignoring LeaderAndIsr request from controller 1 with correlation id 0 epoch 37 for partition [pipeline,1] since its associated leader epoch 27 is old. Current leader epoch is 27 (state.change.logger)
[2016-04-26 12:19:01,344] WARN Broker 2 ignoring LeaderAndIsr request from controller 1 with correlation id 0 epoch 37 for partition [pipeline,2] since its associated leader epoch 30 is old. Current leader epoch is 30 (state.change.logger)
[2016-04-26 12:19:01,344] WARN Broker 2 ignoring LeaderAndIsr request from controller 1 with correlation id 0 epoch 37 for partition [pipeline,0] since its associated leader epoch 30 is old. Current leader epoch is 30 (state.change.logger)
[2016-04-26 12:19:01,345] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:27,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:1,2) for partition [pipeline,1] in response to UpdateMetadata request sent by controller 1 epoch 37 with correlation id 1 (state.change.logger)
[2016-04-26 12:19:01,345] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:30,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,2] in response to UpdateMetadata request sent by controller 1 epoch 37 with correlation id 1 (state.change.logger)
[2016-04-26 12:19:01,345] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:30,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,0] in response to UpdateMetadata request sent by controller 1 epoch 37 with correlation id 1 (state.change.logger)
[2016-04-26 12:19:01,345] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:27,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:1,2) for partition [pipeline,1] in response to UpdateMetadata request sent by controller 1 epoch 37 with correlation id 2 (state.change.logger)
[2016-04-26 12:19:01,345] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:30,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,2] in response to UpdateMetadata request sent by controller 1 epoch 37 with correlation id 2 (state.change.logger)
[2016-04-26 12:19:01,345] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:30,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,0] in response to UpdateMetadata request sent by controller 1 epoch 37 with correlation id 2 (state.change.logger)
[2016-04-26 12:19:01,755] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:27,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:1,2) for partition [pipeline,1] in response to UpdateMetadata request sent by controller 1 epoch 37 with correlation id 3 (state.change.logger)
[2016-04-26 12:44:25,391] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:27,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:1,2) for partition [pipeline,1] in response to UpdateMetadata request sent by controller 1 epoch 38 with correlation id 0 (state.change.logger)
[2016-04-26 12:44:25,391] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:30,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,2] in response to UpdateMetadata request sent by controller 1 epoch 38 with correlation id 0 (state.change.logger)
[2016-04-26 12:44:25,391] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:30,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,0] in response to UpdateMetadata request sent by controller 1 epoch 38 with correlation id 0 (state.change.logger)
[2016-04-26 12:44:25,393] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:27,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:1,2) correlation id 1 from controller 1 epoch 38 for partition [pipeline,1] (state.change.logger)
[2016-04-26 12:44:25,393] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:30,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 1 epoch 38 for partition [pipeline,2] (state.change.logger)
[2016-04-26 12:44:25,393] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:30,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:2,1) correlation id 1 from controller 1 epoch 38 for partition [pipeline,0] (state.change.logger)
[2016-04-26 12:44:25,394] WARN Broker 2 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 38 for partition [pipeline,1] since its associated leader epoch 27 is old. Current leader epoch is 27 (state.change.logger)
[2016-04-26 12:44:25,394] WARN Broker 2 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 38 for partition [pipeline,2] since its associated leader epoch 30 is old. Current leader epoch is 30 (state.change.logger)
[2016-04-26 12:44:25,394] WARN Broker 2 ignoring LeaderAndIsr request from controller 1 with correlation id 1 epoch 38 for partition [pipeline,0] since its associated leader epoch 30 is old. Current leader epoch is 30 (state.change.logger)
[2016-04-26 12:44:25,395] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:27,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:1,2) for partition [pipeline,1] in response to UpdateMetadata request sent by controller 1 epoch 38 with correlation id 2 (state.change.logger)
[2016-04-26 12:44:25,395] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:30,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,2] in response to UpdateMetadata request sent by controller 1 epoch 38 with correlation id 2 (state.change.logger)
[2016-04-26 12:44:25,395] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:30,ControllerEpoch:36),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,0] in response to UpdateMetadata request sent by controller 1 epoch 38 with correlation id 2 (state.change.logger)
[2016-04-26 12:44:25,396] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:28,ControllerEpoch:38),ReplicationFactor:2),AllReplicas:1,2) correlation id 3 from controller 1 epoch 38 for partition [pipeline,1] (state.change.logger)
[2016-04-26 12:44:25,396] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:31,ControllerEpoch:38),ReplicationFactor:2),AllReplicas:2,1) correlation id 3 from controller 1 epoch 38 for partition [pipeline,2] (state.change.logger)
[2016-04-26 12:44:25,397] TRACE Broker 2 received LeaderAndIsr request (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:31,ControllerEpoch:38),ReplicationFactor:2),AllReplicas:2,1) correlation id 3 from controller 1 epoch 38 for partition [pipeline,0] (state.change.logger)
[2016-04-26 12:44:25,398] TRACE Broker 2 handling LeaderAndIsr request correlationId 3 from controller 1 epoch 38 starting the become-follower transition for partition [pipeline,2] (state.change.logger)
[2016-04-26 12:44:25,398] TRACE Broker 2 handling LeaderAndIsr request correlationId 3 from controller 1 epoch 38 starting the become-follower transition for partition [pipeline,0] (state.change.logger)
[2016-04-26 12:44:25,398] TRACE Broker 2 handling LeaderAndIsr request correlationId 3 from controller 1 epoch 38 starting the become-follower transition for partition [pipeline,1] (state.change.logger)
[2016-04-26 12:44:25,398] INFO Broker 2 skipped the become-follower state change after marking its partition as follower with correlation id 3 from controller 1 epoch 38 for partition [pipeline,2] since the new leader 1 is the same as the old leader (state.change.logger)
[2016-04-26 12:44:25,398] INFO Broker 2 skipped the become-follower state change after marking its partition as follower with correlation id 3 from controller 1 epoch 38 for partition [pipeline,0] since the new leader 1 is the same as the old leader (state.change.logger)
[2016-04-26 12:44:25,398] INFO Broker 2 skipped the become-follower state change after marking its partition as follower with correlation id 3 from controller 1 epoch 38 for partition [pipeline,1] since the new leader 1 is the same as the old leader (state.change.logger)
[2016-04-26 12:44:25,399] TRACE Broker 2 completed LeaderAndIsr request correlationId 3 from controller 1 epoch 38 for the become-follower transition for partition [pipeline,2] (state.change.logger)
[2016-04-26 12:44:25,399] TRACE Broker 2 completed LeaderAndIsr request correlationId 3 from controller 1 epoch 38 for the become-follower transition for partition [pipeline,0] (state.change.logger)
[2016-04-26 12:44:25,399] TRACE Broker 2 completed LeaderAndIsr request correlationId 3 from controller 1 epoch 38 for the become-follower transition for partition [pipeline,1] (state.change.logger)
[2016-04-26 12:44:25,400] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:28,ControllerEpoch:38),ReplicationFactor:2),AllReplicas:1,2) for partition [pipeline,1] in response to UpdateMetadata request sent by controller 1 epoch 38 with correlation id 4 (state.change.logger)
[2016-04-26 12:44:25,400] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:31,ControllerEpoch:38),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,2] in response to UpdateMetadata request sent by controller 1 epoch 38 with correlation id 4 (state.change.logger)
[2016-04-26 12:44:25,400] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,LeaderEpoch:31,ControllerEpoch:38),ReplicationFactor:2),AllReplicas:2,1) for partition [pipeline,0] in response to UpdateMetadata request sent by controller 1 epoch 38 with correlation id 4 (state.change.logger)
[2016-04-26 12:44:26,165] TRACE Broker 2 cached leader info (LeaderAndIsrInfo:(Leader:1,ISR:1,2,LeaderEpoch:28,ControllerEpoch:38),ReplicationFactor:2),AllReplicas:1,2) for partition [pipeline,1] in response to UpdateMetadata request sent by controller 1 epoch 38 with correlation id 5 (state.change.logger)
